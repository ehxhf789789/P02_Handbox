{
  "tool_id": "core-tools/llm-chat",
  "version": "1.0.0",
  "display_name": "LLM Chat",
  "description": "Send a prompt to an LLM and receive a response",
  "capability_tags": ["llm.chat", "ai.generate"],
  "input_schema": {
    "ports": [
      { "name": "prompt", "port_type": "string", "description": "User prompt", "required": true },
      { "name": "context", "port_type": "string", "description": "Additional context" },
      { "name": "system", "port_type": "string", "description": "System prompt" }
    ]
  },
  "output_schema": {
    "ports": [
      { "name": "response", "port_type": "string", "description": "LLM response" },
      { "name": "tokens", "port_type": "number", "description": "Tokens used" }
    ]
  },
  "side_effect": "network",
  "required_permissions": ["network.outbound"],
  "cost_hint": { "time": "slow", "monetary": "moderate", "scales_with_input": true, "estimated_tokens": { "input": 500, "output": 500 } },
  "error_model": {
    "error_types": [
      { "code": "RATE_LIMITED", "description": "API rate limit hit", "retryable": true },
      { "code": "API_ERROR", "description": "LLM API error", "retryable": true }
    ],
    "idempotent": false,
    "default_retry": { "max_retries": 3, "backoff_ms": 2000, "backoff_multiplier": 2.0, "max_backoff_ms": 30000 }
  },
  "runtime": { "kind": "native" },
  "config_schema": [
    { "name": "model", "field_type": "string", "description": "LLM model name", "default_value": "claude-sonnet-4-20250514" },
    { "name": "temperature", "field_type": "number", "description": "Sampling temperature", "default_value": 0.7 },
    { "name": "max_tokens", "field_type": "number", "description": "Max output tokens", "default_value": 1024 }
  ]
}
