// ì›Œí¬í”Œë¡œìš° ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ â€” 10,000ê±´ ì‹œë®¬ë ˆì´ì…˜
//
// ëª©ì :
// 1. ë…¸ë“œ ì—°ê²° í˜¸í™˜ì„± ê²€ì¦
// 2. ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì•ˆì •ì„± ê²€ì¦
// 3. ì—ëŸ¬ í•¸ë“¤ë§ ê²€ì¦
// 4. ë°ì´í„° ì „ë‹¬ ë¬´ê²°ì„± ê²€ì¦
// 5. ëª¨ë“  ë…¸ë“œ íƒ€ì… ì»¤ë²„ë¦¬ì§€ í…ŒìŠ¤íŠ¸ (ì§„í™” í•™ìŠµìš©)

use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use std::collections::HashMap;
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;
use tokio::sync::Mutex;

// ============================================================
// í…ŒìŠ¤íŠ¸ ê²°ê³¼ êµ¬ì¡°ì²´
// ============================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestResult {
    pub test_id: u64,
    pub test_name: String,
    pub workflow_type: String,
    pub success: bool,
    pub error_message: Option<String>,
    pub execution_time_ms: u64,
    pub node_count: usize,
    pub edge_count: usize,
    pub nodes_used: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestSummary {
    pub total_tests: u64,
    pub passed: u64,
    pub failed: u64,
    pub success_rate: f64,
    pub avg_execution_time_ms: f64,
    pub errors_by_type: HashMap<String, u64>,
    pub slowest_test_ms: u64,
    pub fastest_test_ms: u64,
    pub node_coverage: HashMap<String, u64>,
    pub nodes_never_tested: Vec<String>,
    pub error_patterns: Vec<ErrorPattern>,
}

/// í•™ìŠµì„ ìœ„í•œ ì˜¤ë¥˜ íŒ¨í„´ ê¸°ë¡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorPattern {
    pub source_node_type: String,
    pub target_node_type: Option<String>,
    pub error_type: String,
    pub error_message: String,
    pub occurrence_count: u64,
    pub suggestion: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StressTestConfig {
    pub test_count: u64,
    pub parallel_count: usize,
    pub include_llm_tests: bool,
    pub include_io_tests: bool,
    pub include_transform_tests: bool,
    pub include_complex_workflows: bool,
    pub ensure_full_coverage: bool,  // NEW: ëª¨ë“  ë…¸ë“œ ìµœì†Œ 1íšŒ í…ŒìŠ¤íŠ¸ ë³´ì¥
}

impl Default for StressTestConfig {
    fn default() -> Self {
        Self {
            test_count: 10000,
            parallel_count: 10,
            include_llm_tests: false, // LLM í…ŒìŠ¤íŠ¸ëŠ” ë¹„ìš© ë¬¸ì œë¡œ ê¸°ë³¸ ë¹„í™œì„±í™”
            include_io_tests: true,
            include_transform_tests: true,
            include_complex_workflows: true,
            ensure_full_coverage: false,
        }
    }
}

// ============================================================
// í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±ê¸°
// ============================================================

/// ë…¸ë“œ íƒ€ì… ì •ì˜
#[derive(Debug, Clone)]
struct NodeType {
    type_name: &'static str,
    category: &'static str,
    input_ports: Vec<(&'static str, &'static str)>, // (name, type)
    output_ports: Vec<(&'static str, &'static str)>,
}

/// ëª¨ë“  ë…¸ë“œ íƒ€ì… ì •ì˜ (í”„ë¡ íŠ¸ì—”ë“œ NodeRegistryì™€ ë™ê¸°í™”)
fn get_node_types() -> Vec<NodeType> {
    vec![
        // ============================================================
        // IO ë…¸ë“œ (5ê°œ)
        // ============================================================
        NodeType {
            type_name: "io.file-read",
            category: "io",
            input_ports: vec![("path", "text")],
            output_ports: vec![("text", "text"), ("metadata", "json")],
        },
        NodeType {
            type_name: "io.file-write",
            category: "io",
            input_ports: vec![("content", "text"), ("path", "text")],
            output_ports: vec![("result", "json")],
        },
        NodeType {
            type_name: "io.file-list",
            category: "io",
            input_ports: vec![("path", "text")],
            output_ports: vec![("files", "json"), ("count", "json")],
        },
        NodeType {
            type_name: "io.file-info",
            category: "io",
            input_ports: vec![("path", "text")],
            output_ports: vec![("info", "json")],
        },
        NodeType {
            type_name: "io.http-request",
            category: "io",
            input_ports: vec![("url", "text"), ("body", "text")],
            output_ports: vec![("body", "text"), ("response", "json")],
        },

        // ============================================================
        // Transform ë…¸ë“œ (9ê°œ)
        // ============================================================
        NodeType {
            type_name: "transform.json-query",
            category: "transform",
            input_ports: vec![("data", "any")],
            output_ports: vec![("result", "json")],
        },
        NodeType {
            type_name: "transform.json-parse",
            category: "transform",
            input_ports: vec![("text", "text")],
            output_ports: vec![("data", "json")],
        },
        NodeType {
            type_name: "transform.json-stringify",
            category: "transform",
            input_ports: vec![("data", "json")],
            output_ports: vec![("text", "text")],
        },
        NodeType {
            type_name: "transform.csv-parse",
            category: "transform",
            input_ports: vec![("text", "text")],
            output_ports: vec![("data", "json"), ("headers", "json")],
        },
        NodeType {
            type_name: "transform.csv-stringify",
            category: "transform",
            input_ports: vec![("data", "json")],
            output_ports: vec![("text", "text")],
        },
        NodeType {
            type_name: "transform.text-split",
            category: "transform",
            input_ports: vec![("text", "text")],
            output_ports: vec![("chunks", "text[]"), ("result", "json")],
        },
        NodeType {
            type_name: "transform.text-regex",
            category: "transform",
            input_ports: vec![("text", "text")],
            output_ports: vec![("result", "json")],
        },
        NodeType {
            type_name: "transform.text-template",
            category: "transform",
            input_ports: vec![("variables", "json")],
            output_ports: vec![("text", "text")],
        },
        NodeType {
            type_name: "transform.xml-parse",
            category: "transform",
            input_ports: vec![("text", "text")],
            output_ports: vec![("data", "json")],
        },

        // ============================================================
        // Storage ë…¸ë“œ (8ê°œ)
        // ============================================================
        NodeType {
            type_name: "storage.kv-get",
            category: "storage",
            input_ports: vec![("key", "text")],
            output_ports: vec![("value", "json"), ("exists", "json")],
        },
        NodeType {
            type_name: "storage.kv-set",
            category: "storage",
            input_ports: vec![("key", "text"), ("value", "any")],
            output_ports: vec![("result", "json")],
        },
        NodeType {
            type_name: "storage.kv-delete",
            category: "storage",
            input_ports: vec![("key", "text")],
            output_ports: vec![("deleted", "json")],
        },
        NodeType {
            type_name: "storage.kv-list",
            category: "storage",
            input_ports: vec![],
            output_ports: vec![("keys", "json")],
        },
        NodeType {
            type_name: "storage.vector-store",
            category: "storage",
            input_ports: vec![("documents", "json")],
            output_ports: vec![("result", "json")],
        },
        NodeType {
            type_name: "storage.vector-search",
            category: "storage",
            input_ports: vec![("query_embedding", "vector")],
            output_ports: vec![("results", "search-result[]")],
        },
        NodeType {
            type_name: "storage.vector-hybrid",
            category: "storage",
            input_ports: vec![("query_embedding", "vector"), ("query_text", "text")],
            output_ports: vec![("results", "search-result[]")],
        },
        NodeType {
            type_name: "storage.sqlite-query",
            category: "storage",
            input_ports: vec![("sql", "text")],
            output_ports: vec![("result", "json")],
        },

        // ============================================================
        // Control ë…¸ë“œ (10ê°œ)
        // ============================================================
        NodeType {
            type_name: "control.if",
            category: "control",
            input_ports: vec![("value", "any")],
            output_ports: vec![("true_out", "any"), ("false_out", "any")],
        },
        NodeType {
            type_name: "control.switch",
            category: "control",
            input_ports: vec![("value", "any")],
            output_ports: vec![("case_1", "any"), ("case_2", "any"), ("case_3", "any"), ("default", "any")],
        },
        NodeType {
            type_name: "control.loop",
            category: "control",
            input_ports: vec![("input", "any")],
            output_ports: vec![("item", "any"), ("index", "json"), ("results", "json")],
        },
        NodeType {
            type_name: "control.forEach",
            category: "control",
            input_ports: vec![("array", "json")],
            output_ports: vec![("item", "any"), ("index", "json"), ("results", "json")],
        },
        NodeType {
            type_name: "control.while",
            category: "control",
            input_ports: vec![("input", "any")],
            output_ports: vec![("result", "any"), ("iterations", "json")],
        },
        NodeType {
            type_name: "control.merge",
            category: "control",
            input_ports: vec![("input_1", "any"), ("input_2", "any"), ("input_3", "any")],
            output_ports: vec![("merged", "json")],
        },
        NodeType {
            type_name: "control.split",
            category: "control",
            input_ports: vec![("input", "any")],
            output_ports: vec![("output_1", "any"), ("output_2", "any"), ("output_3", "any")],
        },
        NodeType {
            type_name: "control.gate",
            category: "control",
            input_ports: vec![("data", "any"), ("gate", "any")],
            output_ports: vec![("output", "any")],
        },
        NodeType {
            type_name: "control.variable-get",
            category: "control",
            input_ports: vec![],
            output_ports: vec![("value", "any")],
        },
        NodeType {
            type_name: "control.variable-set",
            category: "control",
            input_ports: vec![("value", "any")],
            output_ports: vec![("value", "any")],
        },

        // ============================================================
        // LLM ë…¸ë“œ (6ê°œ)
        // ============================================================
        NodeType {
            type_name: "llm.chat",
            category: "llm",
            input_ports: vec![("prompt", "text"), ("system", "text"), ("context", "text")],
            output_ports: vec![("text", "llm-response"), ("usage", "json")],
        },
        NodeType {
            type_name: "llm.embed",
            category: "llm",
            input_ports: vec![("texts", "text[]"), ("text", "text")],
            output_ports: vec![("embeddings", "vector[]"), ("embedding", "vector")],
        },
        NodeType {
            type_name: "llm.structured",
            category: "llm",
            input_ports: vec![("prompt", "text"), ("context", "text")],
            output_ports: vec![("data", "json"), ("text", "text")],
        },
        NodeType {
            type_name: "prompt.template",
            category: "llm",
            input_ports: vec![("variables", "json"), ("context", "text"), ("query", "text")],
            output_ports: vec![("text", "text")],
        },
        NodeType {
            type_name: "prompt.fewshot",
            category: "llm",
            input_ports: vec![("query", "text")],
            output_ports: vec![("text", "text")],
        },
        NodeType {
            type_name: "prompt.chain",
            category: "llm",
            input_ports: vec![("input", "text"), ("previous_response", "text")],
            output_ports: vec![("text", "text")],
        },

        // ============================================================
        // Visualization ë…¸ë“œ (5ê°œ)
        // ============================================================
        NodeType {
            type_name: "viz.table",
            category: "viz",
            input_ports: vec![("data", "json")],
            output_ports: vec![("data", "table-data")],
        },
        NodeType {
            type_name: "viz.chart",
            category: "viz",
            input_ports: vec![("data", "json")],
            output_ports: vec![("data", "chart-data")],
        },
        NodeType {
            type_name: "viz.json",
            category: "viz",
            input_ports: vec![("data", "json")],
            output_ports: vec![("data", "json")],
        },
        NodeType {
            type_name: "viz.text",
            category: "viz",
            input_ports: vec![("text", "text")],
            output_ports: vec![("text", "text")],
        },
        NodeType {
            type_name: "viz.stats",
            category: "viz",
            input_ports: vec![("data", "json")],
            output_ports: vec![("stats", "json")],
        },

        // ============================================================
        // Document ë…¸ë“œ (2ê°œ)
        // ============================================================
        NodeType {
            type_name: "doc.parse",
            category: "doc",
            input_ports: vec![("path", "file-ref")],
            output_ports: vec![("text", "text"), ("metadata", "json"), ("structured_data", "json")],
        },
        NodeType {
            type_name: "doc.convert",
            category: "doc",
            input_ports: vec![("content", "text"), ("source_format", "text")],
            output_ports: vec![("result", "json")],
        },

        // ============================================================
        // Process ë…¸ë“œ (2ê°œ)
        // ============================================================
        NodeType {
            type_name: "process.shell-exec",
            category: "process",
            input_ports: vec![("command", "text")],
            output_ports: vec![("stdout", "text"), ("stderr", "text"), ("exit_code", "json")],
        },
        NodeType {
            type_name: "process.code-eval",
            category: "process",
            input_ports: vec![("code", "text"), ("input", "any")],
            output_ports: vec![("result", "any")],
        },

        // ============================================================
        // Variable ë…¸ë“œ (2ê°œ)
        // ============================================================
        NodeType {
            type_name: "data.constant",
            category: "data",
            input_ports: vec![],
            output_ports: vec![("value", "any")],
        },
        NodeType {
            type_name: "data.input",
            category: "data",
            input_ports: vec![],
            output_ports: vec![("value", "any")],
        },

        // ============================================================
        // Debug ë…¸ë“œ (3ê°œ)
        // ============================================================
        NodeType {
            type_name: "debug.log",
            category: "debug",
            input_ports: vec![("data", "any")],
            output_ports: vec![("data", "any")],
        },
        NodeType {
            type_name: "debug.inspect",
            category: "debug",
            input_ports: vec![("data", "any")],
            output_ports: vec![("info", "json")],
        },
        NodeType {
            type_name: "debug.breakpoint",
            category: "debug",
            input_ports: vec![("data", "any")],
            output_ports: vec![("data", "any")],
        },
    ]
}

/// íƒ€ì… í˜¸í™˜ì„± ì²´í¬
fn are_types_compatible(source_type: &str, target_type: &str) -> bool {
    if source_type == target_type {
        return true;
    }

    // íŠ¹ìˆ˜ í˜¸í™˜ì„± ê·œì¹™ (anyëŠ” ëª¨ë“  íƒ€ì…ê³¼ í˜¸í™˜)
    match (source_type, target_type) {
        ("any", _) | (_, "any") => true,
        ("text", "text[]") | ("text[]", "text") => true,
        ("chunk[]", "text[]") => true,
        ("llm-response", "text") => true,
        ("file-ref", "text") => true,
        ("json", "text") | ("text", "json") => true,
        ("vector", "vector[]") | ("vector[]", "vector") => true,
        ("search-result[]", "json") => true,
        ("table-data", "json") | ("chart-data", "json") => true,
        _ => false,
    }
}

/// ëœë¤ ì›Œí¬í”Œë¡œìš° ìƒì„±
fn generate_random_workflow(
    id: u64,
    node_types: &[NodeType],
    rng: &mut impl rand::Rng,
    include_llm: bool,
) -> (Value, String) {
    use rand::seq::SliceRandom;

    // ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ì„ íƒ
    let patterns = [
        "linear",      // A -> B -> C
        "parallel",    // A -> B, A -> C
        "diamond",     // A -> B, A -> C, B -> D, C -> D
        "complex",     // ë³µì¡í•œ ê·¸ë˜í”„
    ];
    let pattern = patterns[rng.gen_range(0..patterns.len())];

    // LLM ë…¸ë“œ í•„í„°ë§
    let available_nodes: Vec<_> = node_types
        .iter()
        .filter(|n| include_llm || n.category != "llm")
        .collect();

    let mut nodes = Vec::new();
    let mut edges = Vec::new();

    match pattern {
        "linear" => {
            let count = rng.gen_range(2..5);
            for i in 0..count {
                let node_type = available_nodes.choose(rng).unwrap();
                nodes.push(json!({
                    "id": format!("node_{}", i),
                    "type": node_type.type_name,
                    "position": { "x": i * 250, "y": 100 },
                    "data": {
                        "label": format!("{} {}", node_type.type_name, i),
                        "config": {}
                    }
                }));

                if i > 0 {
                    edges.push(json!({
                        "id": format!("edge_{}", i),
                        "source": format!("node_{}", i - 1),
                        "target": format!("node_{}", i)
                    }));
                }
            }
        }
        "parallel" => {
            // ì†ŒìŠ¤ ë…¸ë“œ
            let source_type = available_nodes.choose(rng).unwrap();
            nodes.push(json!({
                "id": "node_0",
                "type": source_type.type_name,
                "position": { "x": 0, "y": 100 },
                "data": { "label": source_type.type_name, "config": {} }
            }));

            // ë³‘ë ¬ ë…¸ë“œë“¤
            let parallel_count = rng.gen_range(2..4);
            for i in 1..=parallel_count {
                let node_type = available_nodes.choose(rng).unwrap();
                nodes.push(json!({
                    "id": format!("node_{}", i),
                    "type": node_type.type_name,
                    "position": { "x": 250, "y": i * 150 },
                    "data": { "label": node_type.type_name, "config": {} }
                }));
                edges.push(json!({
                    "id": format!("edge_{}", i),
                    "source": "node_0",
                    "target": format!("node_{}", i)
                }));
            }
        }
        "diamond" => {
            // ë‹¤ì´ì•„ëª¬ë“œ íŒ¨í„´: 1 -> 2, 1 -> 3, 2 -> 4, 3 -> 4
            for i in 0..4 {
                let node_type = available_nodes.choose(rng).unwrap();
                let (x, y) = match i {
                    0 => (0, 200),
                    1 => (250, 100),
                    2 => (250, 300),
                    3 => (500, 200),
                    _ => (0, 0),
                };
                nodes.push(json!({
                    "id": format!("node_{}", i),
                    "type": node_type.type_name,
                    "position": { "x": x, "y": y },
                    "data": { "label": node_type.type_name, "config": {} }
                }));
            }
            edges.extend(vec![
                json!({"id": "edge_1", "source": "node_0", "target": "node_1"}),
                json!({"id": "edge_2", "source": "node_0", "target": "node_2"}),
                json!({"id": "edge_3", "source": "node_1", "target": "node_3"}),
                json!({"id": "edge_4", "source": "node_2", "target": "node_3"}),
            ]);
        }
        "complex" => {
            let count = rng.gen_range(5..10);
            for i in 0..count {
                let node_type = available_nodes.choose(rng).unwrap();
                nodes.push(json!({
                    "id": format!("node_{}", i),
                    "type": node_type.type_name,
                    "position": { "x": (i % 3) * 250, "y": (i / 3) * 150 },
                    "data": { "label": node_type.type_name, "config": {} }
                }));
            }

            // ëœë¤ ì—£ì§€ ìƒì„± (ì‚¬ì´í´ ë°©ì§€)
            let edge_count = rng.gen_range(count..count * 2);
            for i in 0..edge_count {
                let source = rng.gen_range(0..count - 1);
                let target = rng.gen_range(source + 1..count);
                edges.push(json!({
                    "id": format!("edge_{}", i),
                    "source": format!("node_{}", source),
                    "target": format!("node_{}", target)
                }));
            }
        }
        _ => {}
    }

    let workflow = json!({
        "version": "2.0.0",
        "id": format!("test_workflow_{}", id),
        "meta": {
            "name": format!("Test Workflow {} ({})", id, pattern),
            "description": "Auto-generated test workflow",
            "createdAt": chrono::Utc::now().to_rfc3339(),
            "updatedAt": chrono::Utc::now().to_rfc3339()
        },
        "nodes": nodes,
        "edges": edges
    });

    (workflow, pattern.to_string())
}

// ============================================================
// í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°
// ============================================================

/// ë‹¨ì¼ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
async fn run_single_test(
    test_id: u64,
    workflow: Value,
    workflow_type: String,
) -> TestResult {
    let start = std::time::Instant::now();

    let nodes_array = workflow["nodes"].as_array();
    let nodes = nodes_array.map(|a| a.len()).unwrap_or(0);
    let edges = workflow["edges"].as_array().map(|a| a.len()).unwrap_or(0);

    // ì‚¬ìš©ëœ ë…¸ë“œ íƒ€ì… ìˆ˜ì§‘
    let nodes_used: Vec<String> = nodes_array
        .map(|arr| {
            arr.iter()
                .filter_map(|n| n["type"].as_str().map(String::from))
                .collect()
        })
        .unwrap_or_default();

    // ì›Œí¬í”Œë¡œìš° ê²€ì¦
    let validation_result = validate_workflow(&workflow);

    let (success, error_message) = match validation_result {
        Ok(_) => (true, None),
        Err(e) => (false, Some(e)),
    };

    let execution_time_ms = start.elapsed().as_millis() as u64;

    TestResult {
        test_id,
        test_name: format!("Test_{}", test_id),
        workflow_type,
        success,
        error_message,
        execution_time_ms,
        node_count: nodes,
        edge_count: edges,
        nodes_used,
    }
}

/// ì›Œí¬í”Œë¡œìš° ê²€ì¦
fn validate_workflow(workflow: &Value) -> Result<(), String> {
    // 1. í•„ìˆ˜ í•„ë“œ ê²€ì¦
    if workflow["version"].is_null() {
        return Err("Missing version field".to_string());
    }
    if workflow["nodes"].is_null() {
        return Err("Missing nodes field".to_string());
    }

    // 2. ë…¸ë“œ ê²€ì¦
    let nodes = workflow["nodes"].as_array().ok_or("nodes is not an array")?;
    let node_ids: std::collections::HashSet<_> = nodes
        .iter()
        .filter_map(|n| n["id"].as_str())
        .collect();

    for node in nodes {
        let node_id = node["id"].as_str().ok_or("Node missing id")?;
        let node_type = node["type"].as_str().ok_or(format!("Node {} missing type", node_id))?;

        // ë…¸ë“œ íƒ€ì… ìœ íš¨ì„± ê²€ì‚¬
        let valid_types = get_node_types();
        if !valid_types.iter().any(|t| t.type_name == node_type) {
            return Err(format!("Invalid node type: {}", node_type));
        }
    }

    // 3. ì—£ì§€ ê²€ì¦
    if let Some(edges) = workflow["edges"].as_array() {
        for edge in edges {
            let source = edge["source"].as_str().ok_or("Edge missing source")?;
            let target = edge["target"].as_str().ok_or("Edge missing target")?;

            if !node_ids.contains(source) {
                return Err(format!("Edge references unknown source node: {}", source));
            }
            if !node_ids.contains(target) {
                return Err(format!("Edge references unknown target node: {}", target));
            }
            if source == target {
                return Err(format!("Self-referencing edge: {}", source));
            }
        }

        // ì‚¬ì´í´ ê²€ì¶œ
        if has_cycle(nodes, edges) {
            return Err("Workflow contains a cycle".to_string());
        }
    }

    Ok(())
}

/// ì‚¬ì´í´ ê²€ì¶œ (DFS)
fn has_cycle(nodes: &[Value], edges: &[Value]) -> bool {
    let node_ids: Vec<_> = nodes.iter().filter_map(|n| n["id"].as_str()).collect();
    let mut adj: HashMap<&str, Vec<&str>> = HashMap::new();

    for edge in edges {
        if let (Some(source), Some(target)) = (edge["source"].as_str(), edge["target"].as_str()) {
            adj.entry(source).or_default().push(target);
        }
    }

    let mut visited: HashMap<&str, u8> = HashMap::new(); // 0: unvisited, 1: visiting, 2: visited

    fn dfs<'a>(
        node: &'a str,
        adj: &HashMap<&'a str, Vec<&'a str>>,
        visited: &mut HashMap<&'a str, u8>,
    ) -> bool {
        visited.insert(node, 1);

        if let Some(neighbors) = adj.get(node) {
            for &neighbor in neighbors {
                match visited.get(neighbor) {
                    Some(1) => return true, // Back edge = cycle
                    Some(2) => continue,    // Already fully processed
                    _ => {
                        if dfs(neighbor, adj, visited) {
                            return true;
                        }
                    }
                }
            }
        }

        visited.insert(node, 2);
        false
    }

    for &node_id in &node_ids {
        if visited.get(node_id).unwrap_or(&0) == &0 {
            if dfs(node_id, &adj, &mut visited) {
                return true;
            }
        }
    }

    false
}

// ============================================================
// Tauri ëª…ë ¹
// ============================================================

#[tauri::command]
pub async fn run_workflow_stress_test(
    config: Option<StressTestConfig>,
) -> Result<TestSummary, String> {
    use rand::SeedableRng;

    let config = config.unwrap_or_default();
    let node_types = get_node_types();
    let all_node_type_names: Vec<String> = node_types.iter().map(|n| n.type_name.to_string()).collect();

    let results: Arc<Mutex<Vec<TestResult>>> = Arc::new(Mutex::new(Vec::new()));
    let test_counter = Arc::new(AtomicU64::new(0));

    let semaphore = Arc::new(tokio::sync::Semaphore::new(config.parallel_count));
    let mut handles = Vec::new();

    println!("ğŸš€ Starting stress test with {} tests...", config.test_count);
    println!("ğŸ“‹ Total node types to test: {}", node_types.len());

    // í’€ ì»¤ë²„ë¦¬ì§€ ëª¨ë“œ: ë¨¼ì € ê° ë…¸ë“œ íƒ€ì…ì„ ìµœì†Œ 1íšŒ í…ŒìŠ¤íŠ¸
    let _coverage_test_count = if config.ensure_full_coverage {
        node_types.len() as u64
    } else {
        0
    };

    for i in 0..config.test_count {
        let results = Arc::clone(&results);
        let test_counter = Arc::clone(&test_counter);
        let semaphore = Arc::clone(&semaphore);
        let node_types = node_types.clone();
        let include_llm = config.include_llm_tests;
        let ensure_coverage = config.ensure_full_coverage;

        let handle = tokio::spawn(async move {
            let _permit = semaphore.acquire().await.unwrap();

            // ì‹œë“œ ê¸°ë°˜ RNG (ì¬í˜„ ê°€ëŠ¥)
            let mut rng = rand::rngs::StdRng::seed_from_u64(i);

            // í’€ ì»¤ë²„ë¦¬ì§€ ëª¨ë“œì—ì„œëŠ” ì²˜ìŒ Nê°œì˜ í…ŒìŠ¤íŠ¸ì—ì„œ ê° ë…¸ë“œ íƒ€ì…ì„ í•œ ë²ˆì”© í…ŒìŠ¤íŠ¸
            let (workflow, pattern) = if ensure_coverage && (i as usize) < node_types.len() {
                generate_coverage_workflow(i, &node_types, &mut rng, i as usize)
            } else {
                generate_random_workflow(i, &node_types, &mut rng, include_llm)
            };

            let result = run_single_test(i, workflow, pattern).await;

            let count = test_counter.fetch_add(1, Ordering::SeqCst) + 1;
            if count % 1000 == 0 {
                println!("  Progress: {}/{} tests completed", count, config.test_count);
            }

            results.lock().await.push(result);
        });

        handles.push(handle);
    }

    // ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ ëŒ€ê¸°
    for handle in handles {
        let _ = handle.await;
    }

    // ê²°ê³¼ ì§‘ê³„
    let results = results.lock().await;
    let total = results.len() as u64;
    let passed = results.iter().filter(|r| r.success).count() as u64;
    let failed = total - passed;

    let mut errors_by_type: HashMap<String, u64> = HashMap::new();
    let mut node_coverage: HashMap<String, u64> = HashMap::new();
    let mut error_details: Vec<(String, Option<String>, String)> = Vec::new(); // (node_type, target_type, error_msg)
    let mut total_time: u64 = 0;
    let mut slowest: u64 = 0;
    let mut fastest: u64 = u64::MAX;

    for result in results.iter() {
        total_time += result.execution_time_ms;
        slowest = slowest.max(result.execution_time_ms);
        fastest = fastest.min(result.execution_time_ms);

        // ë…¸ë“œ ì»¤ë²„ë¦¬ì§€ ì¶”ì 
        for node_type in &result.nodes_used {
            *node_coverage.entry(node_type.clone()).or_insert(0) += 1;
        }

        if let Some(ref error) = result.error_message {
            let error_type = error.split(':').next().unwrap_or(error).to_string();
            *errors_by_type.entry(error_type.clone()).or_insert(0) += 1;

            // ì˜¤ë¥˜ ë°œìƒ ë…¸ë“œ íƒ€ì… ê¸°ë¡
            if let Some(first_node) = result.nodes_used.first() {
                let second_node = result.nodes_used.get(1).cloned();
                error_details.push((first_node.clone(), second_node, error.clone()));
            }
        }
    }

    // í…ŒìŠ¤íŠ¸ë˜ì§€ ì•Šì€ ë…¸ë“œ ì°¾ê¸°
    let nodes_never_tested: Vec<String> = all_node_type_names
        .iter()
        .filter(|n| !node_coverage.contains_key(*n))
        .cloned()
        .collect();

    // ì˜¤ë¥˜ íŒ¨í„´ ë¶„ì„
    let error_patterns = analyze_error_patterns(&error_details);

    let summary = TestSummary {
        total_tests: total,
        passed,
        failed,
        success_rate: if total > 0 { passed as f64 / total as f64 } else { 0.0 },
        avg_execution_time_ms: if total > 0 { total_time as f64 / total as f64 } else { 0.0 },
        errors_by_type,
        slowest_test_ms: slowest,
        fastest_test_ms: if fastest == u64::MAX { 0 } else { fastest },
        node_coverage,
        nodes_never_tested,
        error_patterns,
    };

    println!("\nğŸ“Š Stress Test Summary:");
    println!("  Total: {} tests", summary.total_tests);
    println!("  Passed: {} ({:.1}%)", summary.passed, summary.success_rate * 100.0);
    println!("  Failed: {}", summary.failed);
    println!("  Avg Time: {:.2}ms", summary.avg_execution_time_ms);
    println!("  Slowest: {}ms", summary.slowest_test_ms);
    println!("  Fastest: {}ms", summary.fastest_test_ms);
    println!("  Node Types Tested: {}/{}", summary.node_coverage.len(), all_node_type_names.len());

    if !summary.nodes_never_tested.is_empty() {
        println!("\nâš ï¸ Untested node types:");
        for node_type in &summary.nodes_never_tested {
            println!("  - {}", node_type);
        }
    }

    if !summary.errors_by_type.is_empty() {
        println!("\nâš ï¸ Errors by type:");
        for (error_type, count) in &summary.errors_by_type {
            println!("  {}: {}", error_type, count);
        }
    }

    if !summary.error_patterns.is_empty() {
        println!("\nğŸ“š Error patterns for learning:");
        for pattern in &summary.error_patterns {
            println!("  {} -> {:?}: {} ({}íšŒ)",
                pattern.source_node_type,
                pattern.target_node_type,
                pattern.error_type,
                pattern.occurrence_count
            );
        }
    }

    Ok(summary)
}

/// í’€ ì»¤ë²„ë¦¬ì§€ìš© ì›Œí¬í”Œë¡œìš° ìƒì„± (íŠ¹ì • ë…¸ë“œ íƒ€ì… ê°•ì œ í¬í•¨)
fn generate_coverage_workflow(
    id: u64,
    node_types: &[NodeType],
    rng: &mut impl rand::Rng,
    target_index: usize,
) -> (Value, String) {
    use rand::seq::SliceRandom;

    // íƒ€ê²Ÿ ë…¸ë“œë¥¼ ë°˜ë“œì‹œ í¬í•¨
    let target_node = &node_types[target_index];

    // íƒ€ê²Ÿ ë…¸ë“œì™€ í˜¸í™˜ë˜ëŠ” ë…¸ë“œ ì°¾ê¸°
    let compatible_sources: Vec<&NodeType> = node_types.iter()
        .filter(|n| n.type_name != target_node.type_name)
        .filter(|source| {
            source.output_ports.iter().any(|(_, stype)| {
                target_node.input_ports.iter().any(|(_, ttype)| {
                    are_types_compatible(stype, ttype)
                })
            })
        })
        .collect();

    let compatible_targets: Vec<&NodeType> = node_types.iter()
        .filter(|n| n.type_name != target_node.type_name)
        .filter(|target| {
            target_node.output_ports.iter().any(|(_, stype)| {
                target.input_ports.iter().any(|(_, ttype)| {
                    are_types_compatible(stype, ttype)
                })
            })
        })
        .collect();

    let mut nodes = Vec::new();
    let mut edges = Vec::new();

    // ì†ŒìŠ¤ ë…¸ë“œ (ì„ íƒ ì‚¬í•­)
    if !compatible_sources.is_empty() {
        let source = compatible_sources.choose(rng).unwrap();
        nodes.push(json!({
            "id": "node_0",
            "type": source.type_name,
            "position": { "x": 0, "y": 100 },
            "data": { "label": source.type_name, "config": {} }
        }));
    }

    // íƒ€ê²Ÿ ë…¸ë“œ (í•„ìˆ˜)
    let target_id = format!("node_{}", nodes.len());
    nodes.push(json!({
        "id": target_id.clone(),
        "type": target_node.type_name,
        "position": { "x": 250, "y": 100 },
        "data": { "label": target_node.type_name, "config": {} }
    }));

    // ì†ŒìŠ¤ â†’ íƒ€ê²Ÿ ì—£ì§€
    if nodes.len() > 1 {
        edges.push(json!({
            "id": "edge_0",
            "source": "node_0",
            "target": target_id
        }));
    }

    // íƒ€ê²Ÿ ë…¸ë“œì˜ ì¶œë ¥ì„ ë°›ëŠ” ë…¸ë“œ (ì„ íƒ ì‚¬í•­)
    if !compatible_targets.is_empty() && !target_node.output_ports.is_empty() {
        let sink = compatible_targets.choose(rng).unwrap();
        let sink_id = format!("node_{}", nodes.len());
        nodes.push(json!({
            "id": sink_id.clone(),
            "type": sink.type_name,
            "position": { "x": 500, "y": 100 },
            "data": { "label": sink.type_name, "config": {} }
        }));

        edges.push(json!({
            "id": format!("edge_{}", edges.len()),
            "source": target_id,
            "target": sink_id
        }));
    }

    let workflow = json!({
        "version": "2.0.0",
        "id": format!("coverage_test_{}", id),
        "meta": {
            "name": format!("Coverage Test {} ({})", id, target_node.type_name),
            "description": format!("Full coverage test for {}", target_node.type_name),
            "createdAt": chrono::Utc::now().to_rfc3339(),
            "updatedAt": chrono::Utc::now().to_rfc3339()
        },
        "nodes": nodes,
        "edges": edges
    });

    (workflow, format!("coverage:{}", target_node.type_name))
}

/// ì˜¤ë¥˜ íŒ¨í„´ ë¶„ì„
fn analyze_error_patterns(error_details: &[(String, Option<String>, String)]) -> Vec<ErrorPattern> {
    let mut patterns: HashMap<String, ErrorPattern> = HashMap::new();

    for (source, target, error_msg) in error_details {
        let error_type = error_msg.split(':').next().unwrap_or(error_msg).to_string();
        let key = format!("{}:{}:{}", source, target.as_deref().unwrap_or("none"), error_type);

        let suggestion = generate_error_suggestion(&error_type, source, target.as_deref());

        patterns.entry(key.clone())
            .and_modify(|p| p.occurrence_count += 1)
            .or_insert(ErrorPattern {
                source_node_type: source.clone(),
                target_node_type: target.clone(),
                error_type: error_type.clone(),
                error_message: error_msg.clone(),
                occurrence_count: 1,
                suggestion,
            });
    }

    let mut result: Vec<ErrorPattern> = patterns.into_values().collect();
    result.sort_by(|a, b| b.occurrence_count.cmp(&a.occurrence_count));
    result.truncate(20); // ìƒìœ„ 20ê°œ íŒ¨í„´ë§Œ ë°˜í™˜
    result
}

/// ì˜¤ë¥˜ ìœ í˜•ì— ë”°ë¥¸ ê°œì„  ì œì•ˆ ìƒì„±
fn generate_error_suggestion(error_type: &str, source: &str, target: Option<&str>) -> String {
    match error_type {
        "Invalid node type" => format!(
            "ë…¸ë“œ íƒ€ì… '{}'ì´(ê°€) ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. NodeRegistry.register() í˜¸ì¶œì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            source
        ),
        "Missing version field" | "Missing nodes field" =>
            "ì›Œí¬í”Œë¡œìš° JSONì— í•„ìˆ˜ í•„ë“œ(version, nodes)ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ì›Œí¬í”Œë¡œìš° ìƒì„± ì‹œ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ë³´ì¥í•˜ì„¸ìš”.".to_string(),
        "Edge references unknown source node" | "Edge references unknown target node" =>
            "ì—£ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤. ë…¸ë“œ ID ìƒì„± ë° ì—£ì§€ ì—°ê²° ë¡œì§ì„ ê²€í† í•˜ì„¸ìš”.".to_string(),
        "Self-referencing edge" =>
            "ë…¸ë“œê°€ ìê¸° ìì‹ ì„ ì°¸ì¡°í•˜ëŠ” ì—£ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ì—£ì§€ ìƒì„± ì‹œ source â‰  target ê²€ì¦ì„ ì¶”ê°€í•˜ì„¸ìš”.".to_string(),
        "Workflow contains a cycle" =>
            "ì›Œí¬í”Œë¡œìš°ì— ìˆœí™˜ ì°¸ì¡°ê°€ ìˆìŠµë‹ˆë‹¤. DAG(ë°©í–¥ ë¹„ìˆœí™˜ ê·¸ë˜í”„) êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”. ì‚¬ì´í´ ê°ì§€ í›„ ê²½ê³ ë¥¼ í‘œì‹œí•˜ì„¸ìš”.".to_string(),
        "No compatible port types" => format!(
            "ë…¸ë“œ '{}' â†’ '{:?}' ê°„ í˜¸í™˜ë˜ëŠ” í¬íŠ¸ íƒ€ì…ì´ ì—†ìŠµë‹ˆë‹¤. íƒ€ì… í˜¸í™˜ì„± ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ í™•ì¥í•˜ê±°ë‚˜ ì¤‘ê°„ ë³€í™˜ ë…¸ë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.",
            source, target
        ),
        _ => format!(
            "ë…¸ë“œ '{}'ì—ì„œ ë°œìƒí•œ ì˜¤ë¥˜ì…ë‹ˆë‹¤. í•´ë‹¹ ë…¸ë“œì˜ ì„¤ì •ê³¼ ì…ë ¥ ë°ì´í„°ë¥¼ ê²€í† í•˜ì„¸ìš”.",
            source
        ),
    }
}

#[tauri::command]
pub async fn run_node_compatibility_test() -> Result<Value, String> {
    let node_types = get_node_types();
    let mut compatibility_matrix: HashMap<String, HashMap<String, bool>> = HashMap::new();
    let mut issues: Vec<String> = Vec::new();

    println!("ğŸ” Testing node compatibility...");

    for source in &node_types {
        let mut source_compat: HashMap<String, bool> = HashMap::new();

        for target in &node_types {
            // sourceì˜ outputì„ targetì˜ inputì— ì—°ê²° ê°€ëŠ¥í•œì§€ í™•ì¸
            let mut compatible = false;

            for (_, source_type) in &source.output_ports {
                for (_, target_type) in &target.input_ports {
                    if are_types_compatible(source_type, target_type) {
                        compatible = true;
                        break;
                    }
                }
                if compatible {
                    break;
                }
            }

            source_compat.insert(target.type_name.to_string(), compatible);

            // í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ì—°ê²° ê¸°ë¡
            if !compatible && source.type_name != target.type_name {
                issues.push(format!(
                    "{} -> {}: No compatible port types",
                    source.type_name, target.type_name
                ));
            }
        }

        compatibility_matrix.insert(source.type_name.to_string(), source_compat);
    }

    let total_pairs = node_types.len() * node_types.len();
    let compatible_pairs = compatibility_matrix
        .values()
        .flat_map(|m| m.values())
        .filter(|&&v| v)
        .count();

    println!("\nğŸ“Š Node Compatibility Summary:");
    println!("  Total node types: {}", node_types.len());
    println!("  Total pairs: {}", total_pairs);
    println!("  Compatible pairs: {} ({:.1}%)", compatible_pairs, compatible_pairs as f64 / total_pairs as f64 * 100.0);

    Ok(json!({
        "node_count": node_types.len(),
        "total_pairs": total_pairs,
        "compatible_pairs": compatible_pairs,
        "compatibility_rate": compatible_pairs as f64 / total_pairs as f64,
        "matrix": compatibility_matrix,
        "issues": issues
    }))
}
